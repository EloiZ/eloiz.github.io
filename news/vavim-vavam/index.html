<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <hr> <p>layout: post date: 2025-02-24 07:59:00-0400 inline: true related_posts: false New release from the team: <a href="/publications#bartoccioni2025vavim-vavam">VaViM &amp; VaVAM</a>. VaViM is a 1.2B parameter video generative model trained on 1,800+ hours of raw Youtube videos. Its derived video-action model, VaVAM, achieves state-of-the-art results on NeuroNCAP driving benchmark. We open-source <a href="https://github.com/valeoai/VideoActionModel" rel="external nofollow noopener" target="_blank">code, model weights</a>, <a href="https://arxiv.org/abs/2502.15672" rel="external nofollow noopener" target="_blank">training recipes and scaling laws</a>.</p> </body></html>