---
layout: post
date: 2025-02-24 07:59:00-0400
inline: true
related_posts: false
---

New release from the team: [VaViM & VaVAM](/publications#bartoccioni2025vavim-vavam). VaViM is a 1.2B parameter video generative model trained on 1,800+ hours of raw Youtube videos. Its derived video-action model, VaVAM, achieves state-of-the-art results on NeuroNCAP driving benchmark. We open-source [code, model weights](https://github.com/valeoai/VideoActionModel), [training recipes and scaling laws](https://arxiv.org/abs/2502.15672).
